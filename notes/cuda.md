

### CUDA中的优化方法
#### 1. 线程束分化

​	线程束被执行的时候会被分配给相同的指令，处理各自私有的数据；举一个分水果的例子，每次分的水果都是一样的，但是你可以选择吃或者不吃，这个吃和不吃就是分支，在CUDA中支持C语言的控制流，比如if…else, for ,while 等，CUDA中同样支持，但是如果一个线程束中的不同线程包含不同的控制条件，那么当我们执行到这个控制条件是就会面临不同的选择。

​	这里要讲一下CPU了，当我们的程序包含大量的分支判断时，从程序角度来说，程序的逻辑是很复杂的，因为一个分支就会有两条路可以走，如果有10个分支，那么一共有1024条路走，CPU采用流水线话作业，如果每次等到分支执行完再执行下面的指令会造成很大的延迟，所以现在处理器都采用分支预测技术，而CPU的这项技术相对于gpu来说高级了不止一点点，而这也是GPU与CPU的不同，设计初衷就是为了解决不同的问题。

例如对于下面的伪代码

```python
if (con)
{
    //do something
}
else
{
    //do something
}
```

​	假设这段代码是核函数的一部分，那么当一个线程束的32个线程执行这段代码的时候，如果其中16个执行if中的代码段，而另外16个执行else中的代码块，同一个线程束中的线程，执行不同的指令，这叫做线程束的分化。

​	**我们知道在每个指令周期，线程束中的所有线程执行相同的指令**，但是线程束又是分化的，所以这似乎是相悖的，但是事实上这两个可以不矛盾。

​	解决矛盾的办法就是每个线程都执行所有的if和else部分，当一部分con成立的时候，执行if块内的代码，有一部分线程con不成立，那么他们怎么办？继续执行else？不可能的，因为分配命令的调度器就一个，所以这些con不成立的线程等待，就像分水果，你不爱吃，那你就只能看着别人吃，等大家都吃完了，再进行下一轮（也就是下一个指令）线程束分化会产生严重的性能下降。条件分支越多，并行性削弱越严重。
​	**注意线程束分化研究的是一个线程束中的线程，不同线程束中的分支互不影响。**

在GPU中执行的过程如下：

![image-20250917101207413](https://raw.githubusercontent.com/nashpan/image-hosting/main/image-20250917101207413.png)

解决思路是避免同一个线程束内的线程分化，我们可以根据线程编号来设计分支是可以的

例子如下：

```c++
// 原始的会有线程束分化的代码  (当然编译器可能帮我做优化)
__global__ void mathKernel1(float *c)
{
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    
    float a = 0.0;
    float b = 0.0;
    if (tid % 2 == 0)
    {
        a = 100.0f;
    }
    else
    {
        b = 200.0f;
    }
    c[tid] =  a + b;
}

__global__ void mathkernel2(float *c)
{
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    float a = 0.0;
    float b = 0.0;
    if ((tid / warpsize) % 2 == 0)
    {
        a = 100.0f;
    }
    else 
    {
        b = 200.0f;
    }
    c[tid] = a + b;
}
```



